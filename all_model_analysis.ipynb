{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import analysis_relabel_funcs\n",
    "from analysis import read_dfs\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import chi2_contingency\n",
    "from torch.nn import Softmax\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import pickle\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_RELABEL = {\n",
    "    'BERT-Jigsaw': [\"not toxic\", \"toxic\"], \n",
    "    'BERT-SBIC-offensive': [\"Not\", \"Maybe\", \"Offensive\"],\n",
    "    'BERT-SBIC-targetcategory': ['none', 'body', 'culture', 'disabled', 'gender', 'race', 'social', 'victim'], # not used\n",
    "    'BERT-eec-emotion': ['none', 'anger','fear', 'joy', 'sadness'], # not used\n",
    "    'BERT-jigsaw-identityhate': ['Not', \"Yes\"],\n",
    "    'BERT-jigsaw-severetoxic': [\"Not\", \"Yes\"],\n",
    "    'BERT-mdgender-convai-binary': [\"female\", \"male\"],\n",
    "    'BERT-mdgender-convai-ternary': [\"female\", \"male\", \"neutral\"],\n",
    "    'BERT-mdgender-wizard': [\"neutral\", \"female\", \"male\"],\n",
    "    'BERT-rtgender-opgender-annotations': [\"man\", \"woman\"] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _softmax_and_relabel(predictions, categorical_labels):\n",
    "    # takes in a torch.Tensor of predictions and a list of categorical labels, returns a tuple of (softmax tensor, categorical label)\n",
    "    m = Softmax(dim=0)\n",
    "    sm = m(predictions)\n",
    "    return sm, categorical_labels[sm.argmax().item()]\n",
    "\n",
    "def score(labels, predictions):\n",
    "    softmax_preds, category = _softmax_and_relabel(predictions, labels)\n",
    "    # scores are always the difference between the first and last\n",
    "    return softmax_preds[-1] - softmax_preds[0], category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOXIC_MODELS = {\"Cameron/BERT-Jigsaw\", 'Cameron/BERT-SBIC-offensive', 'Cameron/BERT-jigsaw-identityhate', 'Cameron/BERT-jigsaw-severetoxic'}\n",
    "GENDER_MODELS = {'Cameron/BERT-mdgender-convai-binary', 'Cameron/BERT-mdgender-convai-ternary', 'Cameron/BERT-mdgender-wizard', 'Cameron/BERT-rtgender-opgender-annotations'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES=\"\"\"\n",
    "Cameron-BERT-eec-emotion-00:40:36-conv_ai_3-train-eval.out\n",
    "Cameron-BERT-eec-emotion-00:41:55-air_dialogue-train-eval.out\n",
    "Cameron-BERT-eec-emotion-00:42:19-ted_talks_iwslt-train-eval.out\n",
    "Cameron-BERT-eec-emotion-01:06:29-tweet_eval-train-eval.out\n",
    "Cameron-BERT-eec-emotion-01:24:02-ted_talks_iwslt-train-eval.out\n",
    "Cameron-BERT-Jigsaw-00:40:33-conv_ai_3-train-eval.out\n",
    "Cameron-BERT-Jigsaw-00:41:54-air_dialogue-train-eval.out\n",
    "Cameron-BERT-Jigsaw-00:42:14-ted_talks_iwslt-train-eval.out\n",
    "Cameron-BERT-Jigsaw-01:08:42-tweet_eval-train-eval.out\n",
    "Cameron-BERT-Jigsaw-01:15:29-ted_talks_iwslt-train-eval.out\n",
    "Cameron-BERT-jigsaw-identityhate-00:40:35-conv_ai_3-train-eval.out\n",
    "Cameron-BERT-jigsaw-identityhate-00:41:55-air_dialogue-train-eval.out\n",
    "Cameron-BERT-jigsaw-identityhate-00:42:20-ted_talks_iwslt-train-eval.out\n",
    "Cameron-BERT-jigsaw-identityhate-00:43:43-tweet_eval-train-eval.out\n",
    "Cameron-BERT-jigsaw-identityhate-00:53:13-empathetic_dialogues-train-eval.out\n",
    "Cameron-BERT-jigsaw-identityhate-01:32:40-ted_talks_iwslt-train-eval.out\n",
    "Cameron-BERT-jigsaw-severetoxic-00:40:37-conv_ai_3-train-eval.out\n",
    "Cameron-BERT-jigsaw-severetoxic-00:42:01-air_dialogue-train-eval.out\n",
    "Cameron-BERT-jigsaw-severetoxic-00:42:21-ted_talks_iwslt-train-eval.out\n",
    "Cameron-BERT-jigsaw-severetoxic-01:16:40-ted_talks_iwslt-train-eval.out\n",
    "Cameron-BERT-mdgender-convai-binary-00:40:37-conv_ai_3-train-eval.out\n",
    "Cameron-BERT-mdgender-convai-binary-00:42:04-air_dialogue-train-eval.out\n",
    "Cameron-BERT-mdgender-convai-binary-00:42:19-ted_talks_iwslt-train-eval.out\n",
    "Cameron-BERT-mdgender-convai-binary-00:43:41-tweet_eval-train-eval.out\n",
    "Cameron-BERT-mdgender-convai-binary-00:53:18-empathetic_dialogues-train-eval.out\n",
    "Cameron-BERT-mdgender-convai-binary-01:30:30-ted_talks_iwslt-train-eval.out\n",
    "Cameron-BERT-mdgender-convai-ternary-00:40:41-conv_ai_3-train-eval.out\n",
    "Cameron-BERT-mdgender-convai-ternary-00:42:00-air_dialogue-train-eval.out\n",
    "Cameron-BERT-mdgender-convai-ternary-00:42:18-ted_talks_iwslt-train-eval.out\n",
    "Cameron-BERT-mdgender-convai-ternary-01:16:10-ted_talks_iwslt-train-eval.out\n",
    "Cameron-BERT-mdgender-wizard-00:40:34-conv_ai_3-train-eval.out\n",
    "Cameron-BERT-mdgender-wizard-00:41:58-air_dialogue-train-eval.out\n",
    "Cameron-BERT-mdgender-wizard-00:42:15-ted_talks_iwslt-train-eval.out\n",
    "Cameron-BERT-mdgender-wizard-00:43:40-tweet_eval-train-eval.out\n",
    "Cameron-BERT-mdgender-wizard-00:53:08-empathetic_dialogues-train-eval.out\n",
    "Cameron-BERT-mdgender-wizard-01:14:09-ted_talks_iwslt-train-eval.out\n",
    "Cameron-BERT-rtgender-opgender-annotations-00:30:31-conv_ai_3-train-eval.out\n",
    "Cameron-BERT-rtgender-opgender-annotations-00:40:32-conv_ai_3-train-eval.out\n",
    "Cameron-BERT-rtgender-opgender-annotations-00:42:00-air_dialogue-train-eval.out\n",
    "Cameron-BERT-rtgender-opgender-annotations-00:42:14-ted_talks_iwslt-train-eval.out\n",
    "Cameron-BERT-rtgender-opgender-annotations-01:17:11-ted_talks_iwslt-train-eval.out\n",
    "Cameron-BERT-SBIC-offensive-00:40:33-conv_ai_3-train-eval.out\n",
    "Cameron-BERT-SBIC-offensive-00:41:58-air_dialogue-train-eval.out\n",
    "Cameron-BERT-SBIC-offensive-00:42:20-ted_talks_iwslt-train-eval.out\n",
    "Cameron-BERT-SBIC-offensive-00:53:12-empathetic_dialogues-train-eval.out\n",
    "Cameron-BERT-SBIC-offensive-01:08:26-tweet_eval-train-eval.out\n",
    "Cameron-BERT-SBIC-offensive-01:31:48-ted_talks_iwslt-train-eval.out\n",
    "Cameron-BERT-SBIC-targetcategory-00:40:41-conv_ai_3-train-eval.out\n",
    "Cameron-BERT-SBIC-targetcategory-00:42:00-air_dialogue-train-eval.out\n",
    "Cameron-BERT-SBIC-targetcategory-00:42:18-ted_talks_iwslt-train-eval.out\n",
    "Cameron-BERT-SBIC-targetcategory-01:06:42-tweet_eval-train-eval.out\n",
    "Cameron-BERT-SBIC-targetcategory-01:17:08-ted_talks_iwslt-train-eval.out\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type is not classified, please classify Cameron/BERT-eec-emotion with file Cameron-BERT-eec-emotion-00:40:36-conv_ai_3-train-eval.out\n",
      "Model type is not classified, please classify Cameron/BERT-eec-emotion with file Cameron-BERT-eec-emotion-00:41:55-air_dialogue-train-eval.out\n",
      "Model type is not classified, please classify Cameron/BERT-eec-emotion with file Cameron-BERT-eec-emotion-00:42:19-ted_talks_iwslt-train-eval.out\n",
      "Model type is not classified, please classify Cameron/BERT-eec-emotion with file Cameron-BERT-eec-emotion-01:06:29-tweet_eval-train-eval.out\n",
      "Model type is not classified, please classify Cameron/BERT-eec-emotion with file Cameron-BERT-eec-emotion-01:24:02-ted_talks_iwslt-train-eval.out\n",
      "Model name: Cameron/BERT-Jigsaw | eval dataset: conv_ai_3\n",
      "Model name: Cameron/BERT-Jigsaw | eval dataset: air_dialogue\n",
      "Model name: Cameron/BERT-Jigsaw | eval dataset: ted_talks_iwslt\n",
      "Model name: Cameron/BERT-Jigsaw | eval dataset: tweet_eval\n",
      "Model name: Cameron/BERT-Jigsaw | eval dataset: ted_talks_iwslt\n",
      "Model name: Cameron/BERT-jigsaw-identityhate | eval dataset: conv_ai_3\n",
      "Model name: Cameron/BERT-jigsaw-identityhate | eval dataset: air_dialogue\n",
      "Model name: Cameron/BERT-jigsaw-identityhate | eval dataset: ted_talks_iwslt\n",
      "Model name: Cameron/BERT-jigsaw-identityhate | eval dataset: tweet_eval\n",
      "Model name: Cameron/BERT-jigsaw-identityhate | eval dataset: empathetic_dialogues\n",
      "Model name: Cameron/BERT-jigsaw-identityhate | eval dataset: ted_talks_iwslt\n",
      "Model name: Cameron/BERT-jigsaw-severetoxic | eval dataset: conv_ai_3\n",
      "Model name: Cameron/BERT-jigsaw-severetoxic | eval dataset: air_dialogue\n",
      "Model name: Cameron/BERT-jigsaw-severetoxic | eval dataset: ted_talks_iwslt\n",
      "Model name: Cameron/BERT-jigsaw-severetoxic | eval dataset: ted_talks_iwslt\n",
      "Model name: Cameron/BERT-mdgender-convai-binary | eval dataset: conv_ai_3\n",
      "Model name: Cameron/BERT-mdgender-convai-binary | eval dataset: air_dialogue\n",
      "Model name: Cameron/BERT-mdgender-convai-binary | eval dataset: ted_talks_iwslt\n",
      "Model name: Cameron/BERT-mdgender-convai-binary | eval dataset: tweet_eval\n",
      "Model name: Cameron/BERT-mdgender-convai-binary | eval dataset: empathetic_dialogues\n",
      "Model name: Cameron/BERT-mdgender-convai-binary | eval dataset: ted_talks_iwslt\n",
      "Model name: Cameron/BERT-mdgender-convai-ternary | eval dataset: conv_ai_3\n",
      "Model name: Cameron/BERT-mdgender-convai-ternary | eval dataset: air_dialogue\n",
      "Model name: Cameron/BERT-mdgender-convai-ternary | eval dataset: ted_talks_iwslt\n",
      "Model name: Cameron/BERT-mdgender-convai-ternary | eval dataset: ted_talks_iwslt\n",
      "Model name: Cameron/BERT-mdgender-wizard | eval dataset: conv_ai_3\n",
      "Model name: Cameron/BERT-mdgender-wizard | eval dataset: air_dialogue\n",
      "Model name: Cameron/BERT-mdgender-wizard | eval dataset: ted_talks_iwslt\n",
      "Model name: Cameron/BERT-mdgender-wizard | eval dataset: tweet_eval\n",
      "Model name: Cameron/BERT-mdgender-wizard | eval dataset: empathetic_dialogues\n",
      "Model name: Cameron/BERT-mdgender-wizard | eval dataset: ted_talks_iwslt\n",
      "Model name: Cameron/BERT-rtgender-opgender-annotations | eval dataset: conv_ai_3\n",
      "Model name: Cameron/BERT-rtgender-opgender-annotations | eval dataset: conv_ai_3\n",
      "Model name: Cameron/BERT-rtgender-opgender-annotations | eval dataset: air_dialogue\n",
      "Model name: Cameron/BERT-rtgender-opgender-annotations | eval dataset: ted_talks_iwslt\n",
      "Model name: Cameron/BERT-rtgender-opgender-annotations | eval dataset: ted_talks_iwslt\n",
      "Model name: Cameron/BERT-SBIC-offensive | eval dataset: conv_ai_3\n",
      "Model name: Cameron/BERT-SBIC-offensive | eval dataset: air_dialogue\n",
      "Model name: Cameron/BERT-SBIC-offensive | eval dataset: ted_talks_iwslt\n",
      "Model name: Cameron/BERT-SBIC-offensive | eval dataset: empathetic_dialogues\n",
      "Model name: Cameron/BERT-SBIC-offensive | eval dataset: tweet_eval\n",
      "Model name: Cameron/BERT-SBIC-offensive | eval dataset: ted_talks_iwslt\n",
      "Model type is not classified, please classify Cameron/BERT-SBIC-targetcategory with file Cameron-BERT-SBIC-targetcategory-00:40:41-conv_ai_3-train-eval.out\n",
      "Model type is not classified, please classify Cameron/BERT-SBIC-targetcategory with file Cameron-BERT-SBIC-targetcategory-00:42:00-air_dialogue-train-eval.out\n",
      "Model type is not classified, please classify Cameron/BERT-SBIC-targetcategory with file Cameron-BERT-SBIC-targetcategory-00:42:18-ted_talks_iwslt-train-eval.out\n",
      "Model type is not classified, please classify Cameron/BERT-SBIC-targetcategory with file Cameron-BERT-SBIC-targetcategory-01:06:42-tweet_eval-train-eval.out\n",
      "Model type is not classified, please classify Cameron/BERT-SBIC-targetcategory with file Cameron-BERT-SBIC-targetcategory-01:17:08-ted_talks_iwslt-train-eval.out\n"
     ]
    }
   ],
   "source": [
    "eval_files = {}\n",
    "toxic_files = []\n",
    "gender_files = []\n",
    "\n",
    "def create_tup(filename, model_name):\n",
    "    return (model_name.replace(\"Cameron/\", \"\"), \"results/\" + filename)\n",
    "\n",
    "for filename in FILES.strip().split(\"\\n\"):\n",
    "    s = filename.split(\":\")\n",
    "    model_name = s[0][:-3]\n",
    "    model_name = model_name.replace(\"Cameron-\", \"Cameron/\")\n",
    "    eval_dataset_name = s[-1][3:-15]\n",
    "    model_type = None\n",
    "    if eval_dataset_name not in eval_files:\n",
    "        eval_files[eval_dataset_name] = {\"toxic\": [], \"gender\": []}\n",
    "    if model_name in TOXIC_MODELS:\n",
    "        model_type = \"TOXIC\"\n",
    "        eval_files[eval_dataset_name][\"toxic\"].append(create_tup(filename, model_name))\n",
    "        toxic_files.append(filename)\n",
    "    elif model_name in GENDER_MODELS:\n",
    "        model_type = \"GENDER\"\n",
    "        eval_files[eval_dataset_name][\"gender\"].append(create_tup(filename, model_name))\n",
    "        gender_files.append(filename)\n",
    "    else:\n",
    "        print(f\"Model type is not classified, please classify {model_name} with file {filename}\")\n",
    "        continue\n",
    "    print(f\"Model name: {model_name} | eval dataset: {eval_dataset_name}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21 toxic results and 21 gender files\n"
     ]
    }
   ],
   "source": [
    "print(f\"Found {len(toxic_files)} toxic results and {len(gender_files)} gender files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv_ai_3': {'toxic': [('BERT-Jigsaw',\n",
       "    'results/Cameron-BERT-Jigsaw-00:40:33-conv_ai_3-train-eval.out'),\n",
       "   ('BERT-jigsaw-identityhate',\n",
       "    'results/Cameron-BERT-jigsaw-identityhate-00:40:35-conv_ai_3-train-eval.out'),\n",
       "   ('BERT-jigsaw-severetoxic',\n",
       "    'results/Cameron-BERT-jigsaw-severetoxic-00:40:37-conv_ai_3-train-eval.out'),\n",
       "   ('BERT-SBIC-offensive',\n",
       "    'results/Cameron-BERT-SBIC-offensive-00:40:33-conv_ai_3-train-eval.out')],\n",
       "  'gender': [('BERT-mdgender-convai-binary',\n",
       "    'results/Cameron-BERT-mdgender-convai-binary-00:40:37-conv_ai_3-train-eval.out'),\n",
       "   ('BERT-mdgender-convai-ternary',\n",
       "    'results/Cameron-BERT-mdgender-convai-ternary-00:40:41-conv_ai_3-train-eval.out'),\n",
       "   ('BERT-mdgender-wizard',\n",
       "    'results/Cameron-BERT-mdgender-wizard-00:40:34-conv_ai_3-train-eval.out'),\n",
       "   ('BERT-rtgender-opgender-annotations',\n",
       "    'results/Cameron-BERT-rtgender-opgender-annotations-00:30:31-conv_ai_3-train-eval.out'),\n",
       "   ('BERT-rtgender-opgender-annotations',\n",
       "    'results/Cameron-BERT-rtgender-opgender-annotations-00:40:32-conv_ai_3-train-eval.out')]},\n",
       " 'air_dialogue': {'toxic': [('BERT-Jigsaw',\n",
       "    'results/Cameron-BERT-Jigsaw-00:41:54-air_dialogue-train-eval.out'),\n",
       "   ('BERT-jigsaw-identityhate',\n",
       "    'results/Cameron-BERT-jigsaw-identityhate-00:41:55-air_dialogue-train-eval.out'),\n",
       "   ('BERT-jigsaw-severetoxic',\n",
       "    'results/Cameron-BERT-jigsaw-severetoxic-00:42:01-air_dialogue-train-eval.out'),\n",
       "   ('BERT-SBIC-offensive',\n",
       "    'results/Cameron-BERT-SBIC-offensive-00:41:58-air_dialogue-train-eval.out')],\n",
       "  'gender': [('BERT-mdgender-convai-binary',\n",
       "    'results/Cameron-BERT-mdgender-convai-binary-00:42:04-air_dialogue-train-eval.out'),\n",
       "   ('BERT-mdgender-convai-ternary',\n",
       "    'results/Cameron-BERT-mdgender-convai-ternary-00:42:00-air_dialogue-train-eval.out'),\n",
       "   ('BERT-mdgender-wizard',\n",
       "    'results/Cameron-BERT-mdgender-wizard-00:41:58-air_dialogue-train-eval.out'),\n",
       "   ('BERT-rtgender-opgender-annotations',\n",
       "    'results/Cameron-BERT-rtgender-opgender-annotations-00:42:00-air_dialogue-train-eval.out')]},\n",
       " 'ted_talks_iwslt': {'toxic': [('BERT-Jigsaw',\n",
       "    'results/Cameron-BERT-Jigsaw-00:42:14-ted_talks_iwslt-train-eval.out'),\n",
       "   ('BERT-Jigsaw',\n",
       "    'results/Cameron-BERT-Jigsaw-01:15:29-ted_talks_iwslt-train-eval.out'),\n",
       "   ('BERT-jigsaw-identityhate',\n",
       "    'results/Cameron-BERT-jigsaw-identityhate-00:42:20-ted_talks_iwslt-train-eval.out'),\n",
       "   ('BERT-jigsaw-identityhate',\n",
       "    'results/Cameron-BERT-jigsaw-identityhate-01:32:40-ted_talks_iwslt-train-eval.out'),\n",
       "   ('BERT-jigsaw-severetoxic',\n",
       "    'results/Cameron-BERT-jigsaw-severetoxic-00:42:21-ted_talks_iwslt-train-eval.out'),\n",
       "   ('BERT-jigsaw-severetoxic',\n",
       "    'results/Cameron-BERT-jigsaw-severetoxic-01:16:40-ted_talks_iwslt-train-eval.out'),\n",
       "   ('BERT-SBIC-offensive',\n",
       "    'results/Cameron-BERT-SBIC-offensive-00:42:20-ted_talks_iwslt-train-eval.out'),\n",
       "   ('BERT-SBIC-offensive',\n",
       "    'results/Cameron-BERT-SBIC-offensive-01:31:48-ted_talks_iwslt-train-eval.out')],\n",
       "  'gender': [('BERT-mdgender-convai-binary',\n",
       "    'results/Cameron-BERT-mdgender-convai-binary-00:42:19-ted_talks_iwslt-train-eval.out'),\n",
       "   ('BERT-mdgender-convai-binary',\n",
       "    'results/Cameron-BERT-mdgender-convai-binary-01:30:30-ted_talks_iwslt-train-eval.out'),\n",
       "   ('BERT-mdgender-convai-ternary',\n",
       "    'results/Cameron-BERT-mdgender-convai-ternary-00:42:18-ted_talks_iwslt-train-eval.out'),\n",
       "   ('BERT-mdgender-convai-ternary',\n",
       "    'results/Cameron-BERT-mdgender-convai-ternary-01:16:10-ted_talks_iwslt-train-eval.out'),\n",
       "   ('BERT-mdgender-wizard',\n",
       "    'results/Cameron-BERT-mdgender-wizard-00:42:15-ted_talks_iwslt-train-eval.out'),\n",
       "   ('BERT-mdgender-wizard',\n",
       "    'results/Cameron-BERT-mdgender-wizard-01:14:09-ted_talks_iwslt-train-eval.out'),\n",
       "   ('BERT-rtgender-opgender-annotations',\n",
       "    'results/Cameron-BERT-rtgender-opgender-annotations-00:42:14-ted_talks_iwslt-train-eval.out'),\n",
       "   ('BERT-rtgender-opgender-annotations',\n",
       "    'results/Cameron-BERT-rtgender-opgender-annotations-01:17:11-ted_talks_iwslt-train-eval.out')]},\n",
       " 'tweet_eval': {'toxic': [('BERT-Jigsaw',\n",
       "    'results/Cameron-BERT-Jigsaw-01:08:42-tweet_eval-train-eval.out'),\n",
       "   ('BERT-jigsaw-identityhate',\n",
       "    'results/Cameron-BERT-jigsaw-identityhate-00:43:43-tweet_eval-train-eval.out'),\n",
       "   ('BERT-SBIC-offensive',\n",
       "    'results/Cameron-BERT-SBIC-offensive-01:08:26-tweet_eval-train-eval.out')],\n",
       "  'gender': [('BERT-mdgender-convai-binary',\n",
       "    'results/Cameron-BERT-mdgender-convai-binary-00:43:41-tweet_eval-train-eval.out'),\n",
       "   ('BERT-mdgender-wizard',\n",
       "    'results/Cameron-BERT-mdgender-wizard-00:43:40-tweet_eval-train-eval.out')]},\n",
       " 'empathetic_dialogues': {'toxic': [('BERT-jigsaw-identityhate',\n",
       "    'results/Cameron-BERT-jigsaw-identityhate-00:53:13-empathetic_dialogues-train-eval.out'),\n",
       "   ('BERT-SBIC-offensive',\n",
       "    'results/Cameron-BERT-SBIC-offensive-00:53:12-empathetic_dialogues-train-eval.out')],\n",
       "  'gender': [('BERT-mdgender-convai-binary',\n",
       "    'results/Cameron-BERT-mdgender-convai-binary-00:53:18-empathetic_dialogues-train-eval.out'),\n",
       "   ('BERT-mdgender-wizard',\n",
       "    'results/Cameron-BERT-mdgender-wizard-00:53:08-empathetic_dialogues-train-eval.out')]}}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_tab_gender_toxic(eval_file_split, eval_dataset_name, return_one = False):\n",
    "    eval_crosstabs = []\n",
    "    count = 0.0\n",
    "    tot = len(eval_file_split[\"toxic\"]) * len(eval_file_split[\"gender\"])\n",
    "    for toxic_tup in eval_file_split[\"toxic\"]:\n",
    "        toxic_model_name = toxic_tup[0]\n",
    "        toxic_filename = toxic_tup[1]\n",
    "        for gender_tup in eval_file_split[\"gender\"]:\n",
    "            gender_model_name = gender_tup[0]\n",
    "            gender_filename = gender_tup[1]\n",
    "            \n",
    "            # for using sbc and rt_gender for conv_ai\n",
    "            _, _, combined = read_dfs(toxic_filename, \n",
    "                                      gender_filename,\n",
    "                                     suffixes=(\"_\" + toxic_model_name, \"_\" + gender_model_name))\n",
    "            pred_toxic = \"predictions_\" + toxic_model_name\n",
    "            pred_gender = \"predictions_\" + gender_model_name\n",
    "            \n",
    "            print(\"relabeling toxic\")\n",
    "            p = partial(score, MODEL_RELABEL[toxic_model_name])\n",
    "            s = combined[pred_toxic].map(p)\n",
    "            scores_col = f\"scores_{toxic_model_name}\"\n",
    "            category_col = f\"category_{toxic_model_name}\"\n",
    "            \n",
    "            s = pd.DataFrame(s.tolist(), columns=[scores_col, category_col])\n",
    "            s[scores_col] = s[scores_col].map(lambda x: x.item()) # comes back as a tensor, change it to float\n",
    "            combined = combined.join(s)\n",
    "            \n",
    "            print(\"relabeling gender\")\n",
    "            p = partial(score, MODEL_RELABEL[gender_model_name])\n",
    "            s = combined[pred_gender].map(p)\n",
    "            scores_col = f\"scores_{gender_model_name}\"\n",
    "            category_col = f\"category_{gender_model_name}\"\n",
    "            \n",
    "            s = pd.DataFrame(s.tolist(), columns=[scores_col, category_col])\n",
    "            s[scores_col] = s[scores_col].map(lambda x: x.item()) # comes back as a tensor, change it to float\n",
    "            combined = combined.join(s)\n",
    "            \n",
    "            \n",
    "            eval_crosstabs.append({\n",
    "                \"toxic_attr\": (f\"scores_{toxic_model_name}\", f\"category_{toxic_model_name}\"),\n",
    "                \"gender_attr\": (f\"scores_{gender_model_name}\", f\"category_{gender_model_name}\"),\n",
    "                \"df\": combined\n",
    "            })\n",
    "            count += 1.0\n",
    "            print(f\"Crossing {toxic_model_name} x {gender_model_name} for {eval_dataset_name}, finished {count/tot*100}%\")\n",
    "            if return_one:\n",
    "                return eval_crosstabs\n",
    "    return eval_crosstabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing conv_ai_3\n",
      "relabeling toxic\n",
      "relabeling gender\n",
      "Crossing BERT-Jigsaw x BERT-mdgender-convai-binary for conv_ai_3, finished 5.0%\n",
      "relabeling toxic\n",
      "relabeling gender\n",
      "Crossing BERT-Jigsaw x BERT-mdgender-convai-ternary for conv_ai_3, finished 10.0%\n",
      "relabeling toxic\n",
      "relabeling gender\n",
      "Crossing BERT-Jigsaw x BERT-mdgender-wizard for conv_ai_3, finished 15.0%\n",
      "relabeling toxic\n",
      "relabeling gender\n",
      "Crossing BERT-Jigsaw x BERT-rtgender-opgender-annotations for conv_ai_3, finished 20.0%\n",
      "relabeling toxic\n",
      "relabeling gender\n",
      "Crossing BERT-Jigsaw x BERT-rtgender-opgender-annotations for conv_ai_3, finished 25.0%\n",
      "relabeling toxic\n",
      "relabeling gender\n",
      "Crossing BERT-jigsaw-identityhate x BERT-mdgender-convai-binary for conv_ai_3, finished 30.0%\n",
      "relabeling toxic\n",
      "relabeling gender\n",
      "Crossing BERT-jigsaw-identityhate x BERT-mdgender-convai-ternary for conv_ai_3, finished 35.0%\n",
      "relabeling toxic\n",
      "relabeling gender\n",
      "Crossing BERT-jigsaw-identityhate x BERT-mdgender-wizard for conv_ai_3, finished 40.0%\n",
      "relabeling toxic\n",
      "relabeling gender\n",
      "Crossing BERT-jigsaw-identityhate x BERT-rtgender-opgender-annotations for conv_ai_3, finished 45.0%\n",
      "relabeling toxic\n",
      "relabeling gender\n",
      "Crossing BERT-jigsaw-identityhate x BERT-rtgender-opgender-annotations for conv_ai_3, finished 50.0%\n",
      "relabeling toxic\n",
      "relabeling gender\n",
      "Crossing BERT-jigsaw-severetoxic x BERT-mdgender-convai-binary for conv_ai_3, finished 55.00000000000001%\n",
      "relabeling toxic\n",
      "relabeling gender\n",
      "Crossing BERT-jigsaw-severetoxic x BERT-mdgender-convai-ternary for conv_ai_3, finished 60.0%\n",
      "relabeling toxic\n",
      "relabeling gender\n",
      "Crossing BERT-jigsaw-severetoxic x BERT-mdgender-wizard for conv_ai_3, finished 65.0%\n",
      "relabeling toxic\n",
      "relabeling gender\n",
      "Crossing BERT-jigsaw-severetoxic x BERT-rtgender-opgender-annotations for conv_ai_3, finished 70.0%\n",
      "relabeling toxic\n",
      "relabeling gender\n",
      "Crossing BERT-jigsaw-severetoxic x BERT-rtgender-opgender-annotations for conv_ai_3, finished 75.0%\n",
      "relabeling toxic\n",
      "relabeling gender\n",
      "Crossing BERT-SBIC-offensive x BERT-mdgender-convai-binary for conv_ai_3, finished 80.0%\n",
      "relabeling toxic\n",
      "relabeling gender\n",
      "Crossing BERT-SBIC-offensive x BERT-mdgender-convai-ternary for conv_ai_3, finished 85.0%\n",
      "relabeling toxic\n",
      "relabeling gender\n",
      "Crossing BERT-SBIC-offensive x BERT-mdgender-wizard for conv_ai_3, finished 90.0%\n",
      "relabeling toxic\n",
      "relabeling gender\n",
      "Crossing BERT-SBIC-offensive x BERT-rtgender-opgender-annotations for conv_ai_3, finished 95.0%\n",
      "relabeling toxic\n",
      "relabeling gender\n",
      "Crossing BERT-SBIC-offensive x BERT-rtgender-opgender-annotations for conv_ai_3, finished 100.0%\n",
      "Analyzing air_dialogue\n",
      "relabeling toxic\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-b30de3081c3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meval_dataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_f\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Analyzing {eval_dataset_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_tab_gender_toxic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_one\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcrosstabs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-97-25b165567e20>\u001b[0m in \u001b[0;36mcross_tab_gender_toxic\u001b[0;34m(eval_file_split, eval_dataset_name, return_one)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"relabeling toxic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_RELABEL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoxic_model_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_toxic\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mscores_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"scores_{toxic_model_name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mcategory_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"category_{toxic_model_name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   3628\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3629\u001b[0m         \"\"\"\n\u001b[0;32m-> 3630\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3631\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;31m# mapper is a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-b2316d59599e>\u001b[0m in \u001b[0;36mscore\u001b[0;34m(labels, predictions)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msoftmax_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_softmax_and_relabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# scores are always the difference between the first and last\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msoftmax_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msoftmax_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-b2316d59599e>\u001b[0m in \u001b[0;36m_softmax_and_relabel\u001b[0;34m(predictions, categorical_labels)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "crosstabs = []\n",
    "for eval_dataset_name, eval_f in eval_files.items():\n",
    "    print(f\"Analyzing {eval_dataset_name}\")\n",
    "    ct = cross_tab_gender_toxic(eval_f, eval_dataset_name, return_one=False)\n",
    "    crosstabs.append(ct)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(crosstabs, open(f\"{time.time()}-pickle.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_and_generate(ct, dataset_name):\n",
    "    toxic_score_col, toxic_category_col = ct[\"toxic_attr\"]\n",
    "    gender_score_col, gender_category_col = ct[\"gender_attr\"]\n",
    "    std_scaler = StandardScaler()\n",
    "    df = ct[\"df\"]\n",
    "    \n",
    "    # covariance \n",
    "    scores_df = df[[toxic_score_col, gender_score_col]]\n",
    "    scores_df = pd.DataFrame(std_scaler.fit_transform(scores_df), columns=scores_df.columns)\n",
    "    cov = scores_df.cov()\n",
    "    print(f\"{dataset_name} | {toxic_category_col} | {gender_category_col}\")\n",
    "    print(cov)\n",
    "    \n",
    "    # contingency \n",
    "    contingency = pd.crosstab(df[toxic_category_col], df[gender_category_col])\n",
    "    c, p, dof, expected = chi2_contingency(contingency)\n",
    "    print(f\"p-value is {p}\")\n",
    "    \n",
    "    f, ax = plt.subplots(figsize=(9, 6))\n",
    "    sns.heatmap(contingency, annot=True, fmt=\"d\", cmap=\"YlGnBu\")\n",
    "    \n",
    "    print(\"------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_and_generate(ct[0], \"conv_ai_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and change below to load a pickle and use that for analysis!\n",
    "# crosstabs = pickle.load(open(\"####-pickle.p\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
