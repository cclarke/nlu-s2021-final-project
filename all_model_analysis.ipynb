{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install -U swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U pandas\n",
    "# !pip install -U seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sed -i ':a;N;$!ba;s/\\,\\n/\\,/g' results/Cameron*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import analysis_relabel_funcs\n",
    "from analysis import read_dfs, read_outfile\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import chi2_contingency\n",
    "from torch.nn import Softmax\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import pickle\n",
    "import swifter\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_RELABEL = {\n",
    "    'BERT-Jigsaw': [\"not toxic\", \"toxic\"], \n",
    "    'BERT-SBIC-offensive': [\"Not\", \"Maybe\", \"Offensive\"],\n",
    "    'BERT-SBIC-targetcategory': ['none', 'body', 'culture', 'disabled', 'gender', 'race', 'social', 'victim'], # not used\n",
    "    'BERT-eec-emotion': ['none', 'anger','fear', 'joy', 'sadness'], # not used\n",
    "    'BERT-jigsaw-identityhate': ['Not', \"Yes\"],\n",
    "    'BERT-jigsaw-severetoxic': [\"Not\", \"Yes\"],\n",
    "    'BERT-mdgender-convai-binary': [\"female\", \"male\"],\n",
    "    'BERT-mdgender-convai-ternary': [\"female\", \"male\", \"neutral\"],\n",
    "    'BERT-mdgender-wizard': [\"neutral\", \"female\", \"male\"],\n",
    "    'BERT-rtgender-opgender-annotations': [\"man\", \"woman\"] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _softmax_and_relabel(predictions, categorical_labels):\n",
    "    # takes in a torch.Tensor of predictions and a list of categorical labels, returns a tuple of (softmax tensor, categorical label)\n",
    "    m = Softmax(dim=0)\n",
    "    sm = m(predictions)\n",
    "    return sm, categorical_labels[sm.argmax().item()]\n",
    "\n",
    "def score(labels, predictions):\n",
    "    softmax_preds, category = _softmax_and_relabel(predictions, labels)\n",
    "    # scores are always the difference between the first and last\n",
    "    \n",
    "    # for eec-emotion\n",
    "    if labels[1] == \"anger\": \n",
    "        return softmax_preds[1], category\n",
    "    \n",
    "    # for target_category\n",
    "    if labels[1] == \"body\":\n",
    "        return softmax_preds[1], category\n",
    "    \n",
    "    return softmax_preds[-1] - softmax_preds[0], category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOXIC_MODELS = {\"Cameron/BERT-Jigsaw\", 'Cameron/BERT-SBIC-offensive', \n",
    "                #'Cameron/BERT-jigsaw-identityhate', 'Cameron/BERT-jigsaw-severetoxic'\n",
    "               }\n",
    "GENDER_MODELS = {\n",
    "    \"Cameron/BERT-eec-emotion\",\n",
    "    \"Cameron/BERT-SBIC-targetcategory\"\n",
    "    'Cameron/BERT-mdgender-convai-binary', \n",
    "    'Cameron/BERT-mdgender-convai-ternary', \n",
    "    'Cameron/BERT-mdgender-wizard', \n",
    "    'Cameron/BERT-rtgender-opgender-annotations',\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "FILES = glob.glob(\"results/Cameron*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['results/Cameron-BERT-mdgender-wizard-09:24:57-billsum-train-eval.out', 'results/Cameron-BERT-mdgender-convai-binary-00:42:04-air_dialogue-train-eval.out', 'results/Cameron-BERT-eec-emotion-01:06:29-tweet_eval-train-eval.out']\n"
     ]
    }
   ],
   "source": [
    "print(FILES[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: Cameron/BERT-mdgender-wizard | eval dataset: billsum\n",
      "Model type is not classified, please classify Cameron/BERT-mdgender-convai-binary with file results/Cameron-BERT-mdgender-convai-binary-00:42:04-air_dialogue-train-eval.out\n",
      "Model name: Cameron/BERT-eec-emotion | eval dataset: tweet_eval\n",
      "Model name: Cameron/BERT-SBIC-offensive | eval dataset: pubmed_qa\n",
      "Model type is not classified, please classify Cameron/BERT-jigsaw-severetoxic with file results/Cameron-BERT-jigsaw-severetoxic-00:42:01-air_dialogue-train-eval.out\n",
      "Model type is not classified, please classify Cameron/BERT-SBIC-targetcategory with file results/Cameron-BERT-SBIC-targetcategory-00:42:18-ted_talks_iwslt-train-eval.out\n",
      "Model name: Cameron/BERT-Jigsaw | eval dataset: empathetic_dialogues\n",
      "Model type is not classified, please classify Cameron/BERT-jigsaw-identityhate with file results/Cameron-BERT-jigsaw-identityhate-00:42:20-ted_talks_iwslt-train-eval.out\n",
      "Model name: Cameron/BERT-mdgender-convai-ternary | eval dataset: conv_ai_3\n",
      "Model type is not classified, please classify Cameron/BERT-jigsaw-severetoxic with file results/Cameron-BERT-jigsaw-severetoxic-01:16:40-ted_talks_iwslt-train-eval.out\n",
      "Model name: Cameron/BERT-SBIC-offensive | eval dataset: tweet_eval\n",
      "Model name: Cameron/BERT-eec-emotion | eval dataset: ted_talks_iwslt\n",
      "Model name: Cameron/BERT-Jigsaw | eval dataset: billsum\n",
      "Model name: Cameron/BERT-rtgender-opgender-annotations | eval dataset: empathetic_dialogues\n",
      "Model type is not classified, please classify Cameron/BERT-jigsaw-severetoxic with file results/Cameron-BERT-jigsaw-severetoxic-00:42:21-ted_talks_iwslt-train-eval.out\n",
      "Model name: Cameron/BERT-mdgender-convai-ternary | eval dataset: pubmed_qa\n",
      "Model name: Cameron/BERT-SBIC-offensive | eval dataset: wikipedia\n",
      "Model name: Cameron/BERT-rtgender-opgender-annotations | eval dataset: air_dialogue\n",
      "Model type is not classified, please classify Cameron/BERT-jigsaw-identityhate with file results/Cameron-BERT-jigsaw-identityhate-00:41:55-air_dialogue-train-eval.out\n",
      "Model type is not classified, please classify Cameron/BERT-jigsaw-identityhate with file results/Cameron-BERT-jigsaw-identityhate-00:40:35-conv_ai_3-train-eval.out\n",
      "Model name: Cameron/BERT-mdgender-wizard | eval dataset: air_dialogue\n",
      "Model type is not classified, please classify Cameron/BERT-mdgender-convai-binary with file results/Cameron-BERT-mdgender-convai-binary-00:40:37-conv_ai_3-train-eval.out\n",
      "Model name: Cameron/BERT-mdgender-wizard | eval dataset: ted_talks_iwslt\n",
      "Model name: Cameron/BERT-mdgender-convai-ternary | eval dataset: tweet_eval\n",
      "Model type is not classified, please classify Cameron/BERT-jigsaw-identityhate with file results/Cameron-BERT-jigsaw-identityhate-08:54:32-tweet_eval-train-eval.out\n",
      "Model name: Cameron/BERT-rtgender-opgender-annotations | eval dataset: wikipedia\n",
      "Model type is not classified, please classify Cameron/BERT-SBIC-targetcategory with file results/Cameron-BERT-SBIC-targetcategory-09:35:03-wikipedia-train-eval.out\n",
      "Model type is not classified, please classify Cameron/BERT-SBIC-targetcategory with file results/Cameron-BERT-SBIC-targetcategory-09:26:23-pubmed_qa-train-eval.out\n",
      "Model type is not classified, please classify Cameron/BERT-jigsaw-severetoxic with file results/Cameron-BERT-jigsaw-severetoxic-09:27:16-billsum-train-eval.out\n",
      "Model name: Cameron/BERT-Jigsaw | eval dataset: ted_talks_iwslt\n",
      "Model type is not classified, please classify Cameron/BERT-mdgender-convai-binary with file results/Cameron-BERT-mdgender-convai-binary-09:50:56-tweet_eval-train-eval.out\n",
      "Model type is not classified, please classify Cameron/BERT-jigsaw-severetoxic with file results/Cameron-BERT-jigsaw-severetoxic-00:43:48-tweet_eval-train-eval.out\n",
      "Model name: Cameron/BERT-Jigsaw | eval dataset: conv_ai_3\n",
      "Model type is not classified, please classify Cameron/BERT-SBIC-targetcategory with file results/Cameron-BERT-SBIC-targetcategory-01:17:08-ted_talks_iwslt-train-eval.out\n",
      "Model name: Cameron/BERT-mdgender-convai-ternary | eval dataset: yahoo_answers_topics\n",
      "Model name: Cameron/BERT-mdgender-wizard | eval dataset: pubmed_qa\n",
      "Model name: Cameron/BERT-eec-emotion | eval dataset: billsum\n",
      "Model name: Cameron/BERT-eec-emotion | eval dataset: ted_talks_iwslt\n",
      "Model name: Cameron/BERT-rtgender-opgender-annotations | eval dataset: conv_ai_3\n",
      "Model name: Cameron/BERT-mdgender-wizard | eval dataset: ted_talks_iwslt\n",
      "Model type is not classified, please classify Cameron/BERT-jigsaw-identityhate with file results/Cameron-BERT-jigsaw-identityhate-09:27:27-billsum-train-eval.out\n",
      "Model name: Cameron/BERT-eec-emotion | eval dataset: wikipedia\n",
      "Model name: Cameron/BERT-rtgender-opgender-annotations | eval dataset: ted_talks_iwslt\n",
      "Model name: Cameron/BERT-mdgender-convai-ternary | eval dataset: empathetic_dialogues\n",
      "Model type is not classified, please classify Cameron/BERT-mdgender-convai-binary with file results/Cameron-BERT-mdgender-convai-binary-01:30:30-ted_talks_iwslt-train-eval.out\n",
      "Model type is not classified, please classify Cameron/BERT-mdgender-convai-binary with file results/Cameron-BERT-mdgender-convai-binary-00:42:19-ted_talks_iwslt-train-eval.out\n",
      "Model name: Cameron/BERT-mdgender-convai-ternary | eval dataset: ted_talks_iwslt\n",
      "Model name: Cameron/BERT-mdgender-wizard | eval dataset: tweet_eval\n",
      "Model name: Cameron/BERT-eec-emotion | eval dataset: conv_ai_3\n",
      "Model type is not classified, please classify Cameron/BERT-jigsaw-identityhate with file results/Cameron-BERT-jigsaw-identityhate-09:33:58-wikipedia-train-eval.out\n",
      "Model name: Cameron/BERT-Jigsaw | eval dataset: wikipedia\n",
      "Model type is not classified, please classify Cameron/BERT-SBIC-targetcategory with file results/Cameron-BERT-SBIC-targetcategory-00:53:59-empathetic_dialogues-train-eval.out\n",
      "Model type is not classified, please classify Cameron/BERT-jigsaw-identityhate with file results/Cameron-BERT-jigsaw-identityhate-01:32:40-ted_talks_iwslt-train-eval.out\n",
      "Model name: Cameron/BERT-mdgender-convai-ternary | eval dataset: ted_talks_iwslt\n",
      "Model type is not classified, please classify Cameron/BERT-jigsaw-identityhate with file results/Cameron-BERT-jigsaw-identityhate-00:43:43-tweet_eval-train-eval.out\n",
      "Model name: Cameron/BERT-SBIC-offensive | eval dataset: air_dialogue\n",
      "Model type is not classified, please classify Cameron/BERT-jigsaw-identityhate with file results/Cameron-BERT-jigsaw-identityhate-00:53:13-empathetic_dialogues-train-eval.out\n",
      "Model name: Cameron/BERT-mdgender-wizard | eval dataset: conv_ai_3\n",
      "Model name: Cameron/BERT-eec-emotion | eval dataset: air_dialogue\n",
      "Model name: Cameron/BERT-mdgender-wizard | eval dataset: yahoo_answers_topics\n",
      "Model type is not classified, please classify Cameron/BERT-mdgender-convai-binary with file results/Cameron-BERT-mdgender-convai-binary-00:53:18-empathetic_dialogues-train-eval.out\n",
      "Model name: Cameron/BERT-eec-emotion | eval dataset: pubmed_qa\n",
      "Model name: Cameron/BERT-mdgender-convai-ternary | eval dataset: air_dialogue\n",
      "Model name: Cameron/BERT-rtgender-opgender-annotations | eval dataset: billsum\n",
      "Model type is not classified, please classify Cameron/BERT-jigsaw-severetoxic with file results/Cameron-BERT-jigsaw-severetoxic-00:40:37-conv_ai_3-train-eval.out\n",
      "Model name: Cameron/BERT-Jigsaw | eval dataset: tweet_eval\n",
      "Model name: Cameron/BERT-rtgender-opgender-annotations | eval dataset: pubmed_qa\n",
      "Model type is not classified, please classify Cameron/BERT-SBIC-targetcategory with file results/Cameron-BERT-SBIC-targetcategory-00:40:41-conv_ai_3-train-eval.out\n",
      "Model name: Cameron/BERT-Jigsaw | eval dataset: ted_talks_iwslt\n",
      "Model type is not classified, please classify Cameron/BERT-jigsaw-severetoxic with file results/Cameron-BERT-jigsaw-severetoxic-07:26:18-pubmed_qa-train-eval.out\n",
      "Model type is not classified, please classify Cameron/BERT-SBIC-targetcategory with file results/Cameron-BERT-SBIC-targetcategory-09:27:14-billsum-train-eval.out\n",
      "Model type is not classified, please classify Cameron/BERT-SBIC-targetcategory with file results/Cameron-BERT-SBIC-targetcategory-01:06:42-tweet_eval-train-eval.out\n",
      "Model name: Cameron/BERT-Jigsaw | eval dataset: pubmed_qa\n",
      "Model type is not classified, please classify Cameron/BERT-jigsaw-severetoxic with file results/Cameron-BERT-jigsaw-severetoxic-00:53:59-empathetic_dialogues-train-eval.out\n",
      "Model type is not classified, please classify Cameron/BERT-jigsaw-identityhate with file results/Cameron-BERT-jigsaw-identityhate-08:18:00-pubmed_qa-train-eval.out\n",
      "Model type is not classified, please classify Cameron/BERT-mdgender-convai-binary with file results/Cameron-BERT-mdgender-convai-binary-09:30:01-wikipedia-train-eval.out\n",
      "Model name: Cameron/BERT-mdgender-convai-ternary | eval dataset: billsum\n",
      "Model type is not classified, please classify Cameron/BERT-mdgender-convai-binary with file results/Cameron-BERT-mdgender-convai-binary-07:17:12-pubmed_qa-train-eval.out\n",
      "Model type is not classified, please classify Cameron/BERT-SBIC-targetcategory with file results/Cameron-BERT-SBIC-targetcategory-10:03:40-tweet_eval-train-eval.out\n",
      "Model name: Cameron/BERT-SBIC-offensive | eval dataset: tweet_eval\n",
      "Model name: Cameron/BERT-SBIC-offensive | eval dataset: ted_talks_iwslt\n",
      "Model type is not classified, please classify Cameron/BERT-mdgender-convai-binary with file results/Cameron-BERT-mdgender-convai-binary-09:27:16-billsum-train-eval.out\n",
      "Model name: Cameron/BERT-SBIC-offensive | eval dataset: empathetic_dialogues\n",
      "Model type is not classified, please classify Cameron/BERT-SBIC-targetcategory with file results/Cameron-BERT-SBIC-targetcategory-00:42:00-air_dialogue-train-eval.out\n",
      "Model name: Cameron/BERT-Jigsaw | eval dataset: air_dialogue\n",
      "Model name: Cameron/BERT-rtgender-opgender-annotations | eval dataset: ted_talks_iwslt\n",
      "Model name: Cameron/BERT-mdgender-wizard | eval dataset: tweet_eval\n",
      "Model name: Cameron/BERT-SBIC-offensive | eval dataset: conv_ai_3\n",
      "Model name: Cameron/BERT-SBIC-offensive | eval dataset: ted_talks_iwslt\n",
      "Model name: Cameron/BERT-eec-emotion | eval dataset: empathetic_dialogues\n",
      "Model name: Cameron/BERT-Jigsaw | eval dataset: tweet_eval\n",
      "Model name: Cameron/BERT-SBIC-offensive | eval dataset: billsum\n",
      "Model name: Cameron/BERT-mdgender-wizard | eval dataset: wikipedia\n",
      "Model type is not classified, please classify Cameron/BERT-jigsaw-severetoxic with file results/Cameron-BERT-jigsaw-severetoxic-09:34:01-wikipedia-train-eval.out\n",
      "Model name: Cameron/BERT-mdgender-wizard | eval dataset: empathetic_dialogues\n",
      "Model name: Cameron/BERT-rtgender-opgender-annotations | eval dataset: tweet_eval\n",
      "Model name: Cameron/BERT-eec-emotion | eval dataset: tweet_eval\n",
      "Model type is not classified, please classify Cameron/BERT-mdgender-convai-binary with file results/Cameron-BERT-mdgender-convai-binary-00:43:41-tweet_eval-train-eval.out\n",
      "Model name: Cameron/BERT-mdgender-convai-ternary | eval dataset: wikipedia\n"
     ]
    }
   ],
   "source": [
    "eval_files = {}\n",
    "toxic_files = []\n",
    "gender_files = []\n",
    "\n",
    "def create_tup(filename, model_name):\n",
    "    return (model_name.replace(\"Cameron/\", \"\"), filename)\n",
    "\n",
    "for filename in FILES:\n",
    "    s = filename[len(\"results/\"):].split(\":\")\n",
    "    \n",
    "    model_name = s[0][:-3]\n",
    "    model_name = model_name.replace(\"Cameron-\", \"Cameron/\")\n",
    "    eval_dataset_name = s[-1][3:-15]\n",
    "    model_type = None\n",
    "    if eval_dataset_name not in eval_files:\n",
    "        eval_files[eval_dataset_name] = {\"toxic\": [], \"gender\": []}\n",
    "    if model_name in TOXIC_MODELS:\n",
    "        model_type = \"TOXIC\"\n",
    "        eval_files[eval_dataset_name][\"toxic\"].append(create_tup(filename, model_name))\n",
    "        toxic_files.append(filename)\n",
    "    elif model_name in GENDER_MODELS:\n",
    "        model_type = \"GENDER\"\n",
    "        eval_files[eval_dataset_name][\"gender\"].append(create_tup(filename, model_name))\n",
    "        gender_files.append(filename)\n",
    "    else:\n",
    "        print(f\"Model type is not classified, please classify {model_name} with file {filename}\")\n",
    "        continue\n",
    "    print(f\"Model name: {model_name} | eval dataset: {eval_dataset_name}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 toxic results and 40 gender files\n"
     ]
    }
   ],
   "source": [
    "print(f\"Found {len(toxic_files)} toxic results and {len(gender_files)} gender files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toxic': [('BERT-Jigsaw',\n",
       "   'results/Cameron-BERT-Jigsaw-00:40:33-conv_ai_3-train-eval.out'),\n",
       "  ('BERT-SBIC-offensive',\n",
       "   'results/Cameron-BERT-SBIC-offensive-00:40:33-conv_ai_3-train-eval.out')],\n",
       " 'gender': [('BERT-mdgender-convai-ternary',\n",
       "   'results/Cameron-BERT-mdgender-convai-ternary-00:40:41-conv_ai_3-train-eval.out'),\n",
       "  ('BERT-rtgender-opgender-annotations',\n",
       "   'results/Cameron-BERT-rtgender-opgender-annotations-00:40:32-conv_ai_3-train-eval.out'),\n",
       "  ('BERT-eec-emotion',\n",
       "   'results/Cameron-BERT-eec-emotion-00:40:36-conv_ai_3-train-eval.out'),\n",
       "  ('BERT-mdgender-wizard',\n",
       "   'results/Cameron-BERT-mdgender-wizard-00:40:34-conv_ai_3-train-eval.out')]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_files[\"conv_ai_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['yes am interested in obamas family ',\n",
       "       'yes i want to know who made up his family ',\n",
       "       'yes this is what am looking for ', ...,\n",
       "       'no show me the history of it ',\n",
       "       'i would like to know how its evolved over the years ',\n",
       "       'just a timeline of it evolving '], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_dfs(file1, file2, suffixes=(\"_df1\", \"_df2\"), split_tensor=False):\n",
    "    df1 = read_outfile(file1, split_tensor=split_tensor)\n",
    "    df1.drop_duplicates(subset=\"sentence\", inplace=True)\n",
    "    df2 = read_outfile(file2, split_tensor=split_tensor)\n",
    "    df2.drop_duplicates(subset=\"sentence\", inplace=True)\n",
    "    combined_df = df1.merge(df2, on=\"sentence\", suffixes=suffixes)\n",
    "    \n",
    "    return df1, df2, combined_df\n",
    "_, _, c = read_dfs('results/Cameron-BERT-Jigsaw-00:40:33-conv_ai_3-train-eval.out', 'results/Cameron-BERT-eec-emotion-00:40:36-conv_ai_3-train-eval.out')\n",
    "c[\"sentence\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE = {}\n",
    "def get_cache(filename):\n",
    "    if filename in CACHE:\n",
    "        return CACHE[filename]\n",
    "    return None\n",
    "\n",
    "def store_cache(filename, data):\n",
    "    CACHE[filename] = data\n",
    "    \n",
    "def cross_tab_gender_toxic(eval_file_split, eval_dataset_name, return_one = False):\n",
    "    global CACHE\n",
    "    CACHE = {}\n",
    "    eval_crosstabs = []\n",
    "    count = 0.0\n",
    "    tot = len(eval_file_split[\"toxic\"]) * len(eval_file_split[\"gender\"])\n",
    "    for toxic_tup in eval_file_split[\"toxic\"]:\n",
    "        toxic_model_name = toxic_tup[0]\n",
    "        toxic_filename = toxic_tup[1]\n",
    "        for gender_tup in eval_file_split[\"gender\"]:\n",
    "            gender_model_name = gender_tup[0]\n",
    "            gender_filename = gender_tup[1]\n",
    "            \n",
    "            # for using sbc and rt_gender for conv_ai\n",
    "            _, _, combined = read_dfs(toxic_filename, \n",
    "                                      gender_filename,\n",
    "                                     suffixes=(\"_\" + toxic_model_name, \"_\" + gender_model_name))\n",
    "            print(len(combined))\n",
    "            pred_toxic = \"predictions_\" + toxic_model_name\n",
    "            pred_gender = \"predictions_\" + gender_model_name\n",
    "            \n",
    "            print(\"relabeling toxic\")\n",
    "            s = get_cache(toxic_filename)\n",
    "            if s is None:\n",
    "                print(f\"did not find {toxic_filename} in cache\")\n",
    "                p = partial(score, MODEL_RELABEL[toxic_model_name])\n",
    "                s = combined[pred_toxic].swifter.apply(p)\n",
    "                scores_col = f\"scores_{toxic_model_name}\"\n",
    "                category_col = f\"category_{toxic_model_name}\"\n",
    "            \n",
    "                s = pd.DataFrame(s.tolist(), columns=[scores_col, category_col])\n",
    "                s[scores_col] = s[scores_col].swifter.apply(lambda x: x.item()) # comes back as a tensor, change it to float\n",
    "                store_cache(toxic_filename, s)\n",
    "            else:\n",
    "                print(f\"found toxic {toxic_filename} in cache\")\n",
    "            combined = combined.join(s)\n",
    "            print(\"relabeling gender\")\n",
    "            s = get_cache(gender_filename)\n",
    "            if s is None:\n",
    "                print(f\"did not find {gender_filename} in cache\")\n",
    "                p = partial(score, MODEL_RELABEL[gender_model_name])\n",
    "                s = combined[pred_gender].swifter.apply(p)\n",
    "                scores_col = f\"scores_{gender_model_name}\"\n",
    "                category_col = f\"category_{gender_model_name}\"\n",
    "            \n",
    "                s = pd.DataFrame(s.tolist(), columns=[scores_col, category_col])\n",
    "                s[scores_col] = s[scores_col].swifter.apply(lambda x: x.item()) # comes back as a tensor, change it to float\n",
    "                store_cache(gender_filename, s)\n",
    "            else:\n",
    "                print(f\"found gender {gender_filename} in cache\")\n",
    "            combined = combined.join(s)\n",
    "            \n",
    "            \n",
    "            eval_crosstabs.append({\n",
    "                \"toxic_model_name\": toxic_model_name,\n",
    "                \"gender_model_name\": gender_model_name,\n",
    "                \"toxic_attr\": (f\"scores_{toxic_model_name}\", f\"category_{toxic_model_name}\"),\n",
    "                \"gender_attr\": (f\"scores_{gender_model_name}\", f\"category_{gender_model_name}\"),\n",
    "                \"df\": combined\n",
    "            })\n",
    "            count += 1.0\n",
    "            print(f\"Crossing {toxic_model_name} x {gender_model_name} for {eval_dataset_name}, finished {count/tot*100}%\")\n",
    "            if return_one:\n",
    "                return eval_crosstabs\n",
    "    return eval_crosstabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['billsum', 'air_dialogue', 'tweet_eval', 'pubmed_qa', 'ted_talks_iwslt', 'empathetic_dialogues', 'conv_ai_3', 'wikipedia', 'yahoo_answers_topics'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_files.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing billsum\n",
      "103146\n",
      "relabeling toxic\n",
      "did not find results/Cameron-BERT-Jigsaw-09:27:33-billsum-train-eval.out in cache\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d7530b9a454dbf8a24194a0ed2c948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/103146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746a869497d4420d945959e21697b4ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/103146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relabeling gender\n",
      "did not find results/Cameron-BERT-mdgender-wizard-09:24:57-billsum-train-eval.out in cache\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476b7f7c568143e5a74da384b6535159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/103146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0e0edef61640fd8208f2b4294ff2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/103146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossing BERT-Jigsaw x BERT-mdgender-wizard for billsum, finished 12.5%\n",
      "103147\n",
      "relabeling toxic\n",
      "found toxic results/Cameron-BERT-Jigsaw-09:27:33-billsum-train-eval.out in cache\n",
      "relabeling gender\n",
      "did not find results/Cameron-BERT-eec-emotion-09:27:25-billsum-train-eval.out in cache\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6416195291f64fb29ff006ef64b1145c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/103147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c88c445568eb4430a9f152f9730cf40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/103147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossing BERT-Jigsaw x BERT-eec-emotion for billsum, finished 25.0%\n",
      "103147\n",
      "relabeling toxic\n",
      "found toxic results/Cameron-BERT-Jigsaw-09:27:33-billsum-train-eval.out in cache\n",
      "relabeling gender\n",
      "did not find results/Cameron-BERT-rtgender-opgender-annotations-09:24:49-billsum-train-eval.out in cache\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccee0b4851b244bfa8ce51c90010f7bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/103147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a2d645faaf4e968af80d7d099e94b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/103147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossing BERT-Jigsaw x BERT-rtgender-opgender-annotations for billsum, finished 37.5%\n",
      "103147\n",
      "relabeling toxic\n",
      "found toxic results/Cameron-BERT-Jigsaw-09:27:33-billsum-train-eval.out in cache\n",
      "relabeling gender\n",
      "did not find results/Cameron-BERT-mdgender-convai-ternary-09:27:16-billsum-train-eval.out in cache\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc46adab4a24e5b8c224e9e22735cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/103147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127c445bce11463eae418712d5e681fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/103147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossing BERT-Jigsaw x BERT-mdgender-convai-ternary for billsum, finished 50.0%\n",
      "103146\n",
      "relabeling toxic\n",
      "did not find results/Cameron-BERT-SBIC-offensive-09:27:16-billsum-train-eval.out in cache\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c026008d72094a08aa8522fce0da932c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/103146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b98db97307b4fac8f79c0d0c790de92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/103146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relabeling gender\n",
      "found gender results/Cameron-BERT-mdgender-wizard-09:24:57-billsum-train-eval.out in cache\n",
      "Crossing BERT-SBIC-offensive x BERT-mdgender-wizard for billsum, finished 62.5%\n",
      "103147\n",
      "relabeling toxic\n",
      "found toxic results/Cameron-BERT-SBIC-offensive-09:27:16-billsum-train-eval.out in cache\n",
      "relabeling gender\n",
      "found gender results/Cameron-BERT-eec-emotion-09:27:25-billsum-train-eval.out in cache\n",
      "Crossing BERT-SBIC-offensive x BERT-eec-emotion for billsum, finished 75.0%\n",
      "103147\n",
      "relabeling toxic\n",
      "found toxic results/Cameron-BERT-SBIC-offensive-09:27:16-billsum-train-eval.out in cache\n",
      "relabeling gender\n",
      "found gender results/Cameron-BERT-rtgender-opgender-annotations-09:24:49-billsum-train-eval.out in cache\n",
      "Crossing BERT-SBIC-offensive x BERT-rtgender-opgender-annotations for billsum, finished 87.5%\n",
      "103147\n",
      "relabeling toxic\n",
      "found toxic results/Cameron-BERT-SBIC-offensive-09:27:16-billsum-train-eval.out in cache\n",
      "relabeling gender\n",
      "found gender results/Cameron-BERT-mdgender-convai-ternary-09:27:16-billsum-train-eval.out in cache\n",
      "Crossing BERT-SBIC-offensive x BERT-mdgender-convai-ternary for billsum, finished 100.0%\n",
      "Analyzing air_dialogue\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-50152d1a5143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Analyzing {eval_dataset_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_tab_gender_toxic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_one\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m#pickle.dump((eval_dataset_name, ct), open(f\"crosstabs-pickle-{eval_dataset_name}.p\", \"wb\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mcrosstabs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-e0392b121754>\u001b[0m in \u001b[0;36mcross_tab_gender_toxic\u001b[0;34m(eval_file_split, eval_dataset_name, return_one)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# for using sbc and rt_gender for conv_ai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             _, _, combined = read_dfs(toxic_filename, \n\u001b[0m\u001b[1;32m     25\u001b[0m                                       \u001b[0mgender_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                                      suffixes=(\"_\" + toxic_model_name, \"_\" + gender_model_name))\n",
      "\u001b[0;32m<ipython-input-13-cc16d3830b20>\u001b[0m in \u001b[0;36mread_dfs\u001b[0;34m(file1, file2, suffixes, split_tensor)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_dfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_df1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_df2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_outfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sentence\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_outfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sentence\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/pw1329/nlu-s2021-final-project/analysis.py\u001b[0m in \u001b[0;36mread_outfile\u001b[0;34m(outfile_name, delimiter, skiprows, split_tensor)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_outfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     df = pd.read_csv(\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0moutfile_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/transformers-dev/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/transformers-dev/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/transformers-dev/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1055\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/transformers-dev/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2059\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/transformers-dev/lib/python3.9/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m     \"\"\"\n\u001b[1;32m    539\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "crosstabs = []\n",
    "for eval_dataset_name, eval_f in eval_files.items():\n",
    "#     if eval_dataset_name != \"conv_ai_3\":\n",
    "#         continue\n",
    "#     if eval_dataset_name == \"air_dialogue\" or eval_dataset_name == \"empathetic_dialogues\":\n",
    "#         print(f'ignoring {eval_dataset_name} for now')\n",
    "#         continue\n",
    "    print(f\"Analyzing {eval_dataset_name}\")\n",
    "    try:\n",
    "        ct = cross_tab_gender_toxic(eval_f, eval_dataset_name, return_one=False)\n",
    "        pickle.dump((eval_dataset_name, ct), open(f\"crosstabs-pickle-{eval_dataset_name}.p\", \"wb\"))\n",
    "        crosstabs.append((eval_dataset_name, ct))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        raise \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(crosstabs, open(\"crosstabs-pickle-jigsaw-target-category.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(crosstabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_and_generate(ct, dataset_name):\n",
    "    toxic_model_name = ct[\"toxic_model_name\"]\n",
    "    gender_model_name = ct[\"gender_model_name\"]\n",
    "    toxic_score_col, toxic_category_col = ct[\"toxic_attr\"]\n",
    "    gender_score_col, gender_category_col = ct[\"gender_attr\"]\n",
    "    std_scaler = StandardScaler()\n",
    "    df = ct[\"df\"]\n",
    "    # covariance \n",
    "    scores_df = df[[toxic_score_col, gender_score_col]]\n",
    "    try:\n",
    "        scores_df = pd.DataFrame(std_scaler.fit_transform(scores_df), columns=scores_df.columns)\n",
    "    except Exception as e:\n",
    "        print(df)\n",
    "        print(f\"FAILED TO GENERATE COVARIANCE FOR {dataset_name} WITH MODELS TOXIC: {toxic_model_name} GENDER: {gender_model_name}\")\n",
    "        return \n",
    "    cov = scores_df.cov()\n",
    "    print(f\"{dataset_name} | {toxic_category_col} | {gender_category_col}\")\n",
    "    print(cov)\n",
    "    \n",
    "    # contingency \n",
    "    contingency = pd.crosstab(df[toxic_category_col], df[gender_category_col])\n",
    "    c, p, dof, expected = chi2_contingency(contingency)\n",
    "    print(f\"p-value is {p}\")\n",
    "    \n",
    "    f, ax = plt.subplots(figsize=(9, 6))\n",
    "    sns.heatmap(contingency, annot=True, fmt=\"d\", cmap=\"YlGnBu\").set_title(dataset_name)\n",
    "    \n",
    "    print(\"------------------------------\")\n",
    "    return contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for ct in crosstabs[0]:\n",
    "#     scale_and_generate(ct, \"conv_ai_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and change below to load a pickle and use that for analysis!\n",
    "# crosstabs = pickle.load(open(\"crosstabs-pickle.p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c = []\n",
    "for eval_dataset_name, ct_list in crosstabs: \n",
    "    for ct in ct_list:\n",
    "        contingency = scale_and_generate(ct, eval_dataset_name)\n",
    "        c.append(contingency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
